before_script:
  - docker info
  - nvidia-smi


# template

.build:
  script:
    - docker build --pull --tag ${CI_JOB_ID} $CI_DOCKER_BUILD_ARGS .
    - docker run --rm --gpus all --env JULIA_CUDA_MEMORY_LIMIT $CI_DOCKER_RUN_ARGS $CI_JOB_ID --volume "/usr/lib/x86_64-linux-gnu/nvidia/current/libcuda.so.450.57:/usr/lib/x86_64-linux-gnu/libcuda.so.1" -e '
          run(`id`);
          using CUDA;
          CUDA.versioninfo();
          using Pkg;
          Pkg.test(collect(keys(Pkg.installed())));'
    - docker rmi ${CI_JOB_ID}


# CUDA versions

cuda:11.0:
  extends: .build
  variables:
    CI_DOCKER_BUILD_ARGS: '--build-arg IMAGE=nvidia/cuda:11.0-cudnn8-devel-ubuntu18.04'

cuda:10.2:
  extends: .build
  variables:
    CI_DOCKER_BUILD_ARGS: '--build-arg IMAGE=nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04'

cuda:10.1:
  extends: .build
  variables:
    CI_DOCKER_BUILD_ARGS: '--build-arg IMAGE=nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04'

cuda:10.0:
  extends: .build
  variables:
    CI_DOCKER_BUILD_ARGS: '--build-arg IMAGE=nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04'

cuda:9.2:
  extends: .build
  variables:
    CI_DOCKER_BUILD_ARGS: '--build-arg IMAGE=nvidia/cuda:9.2-cudnn7-devel-ubuntu18.04'


# special tests

user:
  extends: .build
  variables:
    CI_DOCKER_RUN_ARGS: '--user 1000:1000'
